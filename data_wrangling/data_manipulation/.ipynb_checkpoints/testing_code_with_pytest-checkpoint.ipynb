{
 "cells": [
  {
   "cell_type": "raw",
   "id": "73cea8c9",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Pytest for testing\"\n",
    "author: \"Kedar Dabhadkar\"\n",
    "date: 2021-06-09T05:46:18.464519\n",
    "description: \"How you can use Pytest to test your Python code\"\n",
    "type: technical_note\n",
    "draft: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7ef7b1",
   "metadata": {},
   "source": [
    "### Pytest for Testing Python code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d8efdd",
   "metadata": {},
   "source": [
    "Every line line of code is one more reason why your entire software might crash. We sometimes don't realize the importance of testing our code until our code becomes a part of a production codebase. Pytest is the most widely used framework for unit testing in Python. Here's how you can easily unit test your code with pytest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65d4583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0c997b",
   "metadata": {},
   "source": [
    "#### Write the code and corresponding tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522b9471",
   "metadata": {},
   "source": [
    "As an example, let's write a simple function to check if a number is even. This function returns Boolean - True or False. Let's pass a test case and see if it returns the results that we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b046a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting check_if_even.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile check_if_even.py\n",
    "\n",
    "def check_if_even(a):\n",
    "    \"\"\"\n",
    "    Returns True if a is an even number\n",
    "    \"\"\"\n",
    "    return a % 2 == 0\n",
    "\n",
    "def test_check_if_even():\n",
    "    \"\"\"\n",
    "    Define test cases\n",
    "    \"\"\"\n",
    "    # a = 2. Expected value is True\n",
    "    a = 2\n",
    "    is_even = check_if_even(a)\n",
    "    assert is_even == True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26416fb",
   "metadata": {},
   "source": [
    "#### Run the test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecff0e58",
   "metadata": {},
   "source": [
    "Pytest reads the Python scripts and understands that any function that starts with 'test_' is the test function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7b3d709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.7.10, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\n",
      "rootdir: /home/kedardabhadkar/Notes/data_wrangling/data_manipulation\n",
      "plugins: anyio-2.0.2, Faker-8.5.1, dash-1.20.0\n",
      "collected 1 item                                                               \u001b[0m\n",
      "\n",
      "check_if_even.py \u001b[32m.\u001b[0m\u001b[32m                                                       [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.04s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest check_if_even.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4073137",
   "metadata": {},
   "source": [
    "#### Run multiple tests cases at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1da15bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting check_if_even.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile check_if_even.py\n",
    "\n",
    "import pytest\n",
    "\n",
    "testdata = [\n",
    "    (2, True),\n",
    "    (3, False),\n",
    "    (4, True),\n",
    "    (5, True) # We expect this test to fail\n",
    "    ]\n",
    "\n",
    "def check_if_even(a):\n",
    "    \"\"\"\n",
    "    Returns True if 'a' is an even number\n",
    "    \"\"\"\n",
    "    return a % 2 == 0\n",
    "\n",
    "@pytest.mark.parametrize('sample, expected_output', testdata)\n",
    "def test_check_if_even(sample, expected_output):\n",
    "    \"\"\"\n",
    "    Define test cases\n",
    "    \"\"\"\n",
    "\n",
    "    assert check_if_even(sample) == expected_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54e49543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.7.10, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\n",
      "rootdir: /home/kedardabhadkar/Notes/data_wrangling/data_manipulation\n",
      "plugins: anyio-2.0.2, Faker-8.5.1, dash-1.20.0\n",
      "collected 4 items                                                              \u001b[0m\n",
      "\n",
      "check_if_even.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[31m                                                    [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m__________________________ test_check_if_even[5-True] __________________________\u001b[0m\n",
      "\n",
      "sample = 5, expected_output = True\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m'\u001b[39;49;00m\u001b[33msample, expected_output\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, testdata)\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_check_if_even\u001b[39;49;00m(sample, expected_output):\n",
      "        \u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Define test cases\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "    \n",
      ">       \u001b[94massert\u001b[39;49;00m check_if_even(sample) == expected_output\n",
      "\u001b[1m\u001b[31mE       assert False == True\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where False = check_if_even(5)\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mcheck_if_even.py\u001b[0m:23: AssertionError\n",
      "=========================== short test summary info ============================\n",
      "FAILED check_if_even.py::test_check_if_even[5-True] - assert False == True\n",
      "\u001b[31m========================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m3 passed\u001b[0m\u001b[31m in 0.14s\u001b[0m\u001b[31m ==========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest check_if_even.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3ab7c1",
   "metadata": {},
   "source": [
    "And as expected, the first 3 test cases passed and the last one failed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1247fc8c",
   "metadata": {},
   "source": [
    "#### How do we structure our code after integrating with pytest?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8acc77b",
   "metadata": {},
   "source": [
    "Although there are multiple ways in which you can structure your code, this is the way that I personally prefer it. This structure logically separates your tests from the rest of the soruce code."
   ]
  },
  {
   "cell_type": "raw",
   "id": "7425937e",
   "metadata": {},
   "source": [
    "project/\n",
    "├── src\n",
    "│   └── check_if_even.py\n",
    "└── tests\n",
    "    └── test_code.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85bef2b",
   "metadata": {},
   "source": [
    "When applied to our toy example, this is what each of these two scripts would look like "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63ac26ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting project/src/check_if_even.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile project/src/check_if_even.py\n",
    "\n",
    "def check_if_even(a):\n",
    "    \"\"\"\n",
    "    Returns True if 'a' is an even number\n",
    "    \"\"\"\n",
    "    return a % 2 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "793ed718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting project/tests/test_code.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile project/tests/test_code.py\n",
    "\n",
    "import pytest\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\n",
    "    os.path.abspath(os.path.join(os.path.dirname(__file__), os.path.pardir)))\n",
    "\n",
    "from src.check_if_even import check_if_even\n",
    "\n",
    "testdata = [\n",
    "    (2, True),\n",
    "    (3, False),\n",
    "    (4, True),\n",
    "    (5, True) # We expect this test to fail\n",
    "    ]\n",
    "\n",
    "@pytest.mark.parametrize('sample, expected_output', testdata)\n",
    "def test_check_if_even(sample, expected_output):\n",
    "    \"\"\"\n",
    "    Define test cases\n",
    "    \"\"\"\n",
    "\n",
    "    assert check_if_even(sample) == expected_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f31fd1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.7.10, pytest-6.2.4, py-1.10.0, pluggy-0.13.1\n",
      "rootdir: /home/kedardabhadkar/Notes/data_wrangling/data_manipulation\n",
      "plugins: anyio-2.0.2, Faker-8.5.1, dash-1.20.0\n",
      "collected 4 items                                                              \u001b[0m\n",
      "\n",
      "project/tests/test_code.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[31m                                          [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m__________________________ test_check_if_even[5-True] __________________________\u001b[0m\n",
      "\n",
      "sample = 5, expected_output = True\n",
      "\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m'\u001b[39;49;00m\u001b[33msample, expected_output\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, testdata)\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_check_if_even\u001b[39;49;00m(sample, expected_output):\n",
      "        \u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Define test cases\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "    \n",
      ">       \u001b[94massert\u001b[39;49;00m check_if_even(sample) == expected_output\n",
      "\u001b[1m\u001b[31mE       assert False == True\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where False = check_if_even(5)\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mproject/tests/test_code.py\u001b[0m:25: AssertionError\n",
      "=========================== short test summary info ============================\n",
      "FAILED project/tests/test_code.py::test_check_if_even[5-True] - assert False ...\n",
      "\u001b[31m========================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m3 passed\u001b[0m\u001b[31m in 0.14s\u001b[0m\u001b[31m ==========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest project/tests/test_code.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae56377",
   "metadata": {},
   "source": [
    "#### Read more"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a968e292",
   "metadata": {},
   "source": [
    "[1] https://towardsdatascience.com/pytest-for-data-scientists-2990319e55e6 <br>\n",
    "[2] https://docs.pytest.org/en/6.2.x/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
